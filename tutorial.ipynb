{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dc8dd76",
   "metadata": {},
   "source": [
    "# 脳波データを活用した運動意図の判定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2474efb9",
   "metadata": {},
   "source": [
    "これは「脳波データを活用した運動意図の判定」の分析・モデリングチュートリアルである. 必要に応じて分析・モデリングをする際の参考にされたい."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9199988",
   "metadata": {},
   "source": [
    "## 前準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93728373",
   "metadata": {},
   "source": [
    "### データの準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b555242e",
   "metadata": {},
   "source": [
    "配布されている`train_0.zip~train_5.zip`, `train_master.csv`, `test_0.zip~test_2.zip`をダウンロードし, このノートブックと同じディレクトリに配置して, zipファイルは解凍する. 解凍後以下のようなディレクトリができていることを確認.\n",
    "\n",
    "```\n",
    ".\n",
    "├── train              # 学習用データ\n",
    "│   ├── train_000.csv\n",
    "│   ├── ...\n",
    "│   └── train_2247.csv\n",
    "├── test               # 評価用データ\n",
    "│   ├── test_000.csv\n",
    "│   ├── ...\n",
    "│   └── test_757.csv\n",
    "├── train_master.csv   # 学習用アノテーションデータ\n",
    "└── tutorial.ipynb     # このノートブックファイル\n",
    "```\n",
    "\n",
    "各データの定義については配布されている`README.pdf`を参照すること."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd9ff32",
   "metadata": {},
   "source": [
    "#### Google Colaboratoryを使う場合"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5df07b",
   "metadata": {},
   "source": [
    "自身のドライブなどにこのjupyternotebookファイルをアップロードして立ち上げることでGoogle Colaboratoryを起動し, `/content`以下に`train_0.zip~train_5.zip`, `train_master.csv`, `test_0.zip~test_2.zip`をアップロードする. その後下記コマンドを実行することで, zipファイルは解凍される. またはGoogle Driveをマウントしてもよい."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398cef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 現在のディレクトリを表示\n",
    "! pwd # デフォルトなら`/content`と表示される\n",
    "! ls  # train_*.zip, test_*.zipが表示されることを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f905e190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Driveをマウントしているならターミナルからドライブのディレクトリへ移動して`unzip`を実行する.\n",
    "# または解凍したものをフォルダごとドライブにアップロードしておく(その場合は下記コマンドを実行する必要はない.).\n",
    "! unzip train_*.zip\n",
    "! unzip test_*.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50321c39",
   "metadata": {},
   "source": [
    "### ライブラリのインストール"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf22da5a",
   "metadata": {},
   "source": [
    "これから行う分析やモデリングに必要なライブラリをインストールする. 主に必要なライブラリは以下の通り.\n",
    "\n",
    "- pandas\n",
    "- numpy\n",
    "- matplotlib\n",
    "- mne\n",
    "- braindecode\n",
    "\n",
    "インストールされていないなら下記コマンドでインストールすること."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53d6c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install braindecode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bfbcd9",
   "metadata": {},
   "source": [
    "`braindecode`をインストールすることで他のライブラリは自動的にインストールされる(依存ライブラリのため)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6dd194",
   "metadata": {},
   "source": [
    "## ライブラリのインポートと設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c21ccd",
   "metadata": {},
   "source": [
    "今後の作業で必要になる「道具」（＝Pythonのライブラリ）を用意する. また, データやファイルを保存しているフォルダの場所（ルートディレクトリ）を決めておく. これを最初にやっておくと, 今後データを読み込んだり保存したりするときに, 毎回場所を指定しなくてすむので便利である.\n",
    "\n",
    "下記セルのコメントアウトにてインポートしているライブラリの役割を簡単に確認されたい."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6c47a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ分析や機械学習に使う道具（ライブラリ）を準備します\n",
    "import os                          # ファイルやフォルダを操作する\n",
    "import pandas as pd                # 表形式のデータを扱う\n",
    "import numpy as np                 # 数値計算や配列の操作をする\n",
    "import matplotlib.pyplot as plt    # グラフや図を描く\n",
    "import mne                         # 脳波データを分析する\n",
    "\n",
    "# braindecodeは脳波などの時系列信号用・ディープラーニングモデルを使うためのライブラリです.\n",
    "# EEGClassifierはPyTorchモデルを簡単に分類問題に使えるようにまとめたクラスです.\n",
    "from braindecode import EEGClassifier\n",
    "\n",
    "# skorchはPyTorchをscikit-learnのような使い方で便利にするためのラッパーです.\n",
    "# ValidSplitはデータを自動で訓練用と検証用に分割して管理するためのクラスです.\n",
    "from skorch.dataset import ValidSplit\n",
    "\n",
    "\n",
    "# データの読み込み場所, 結果の保存場所を決めておきます\n",
    "DATA_DIR = '.'    # データファイルがあるフォルダ（ここではカレントフォルダを指定. Google Colaboratoryを使っていてGoogle Driveをマウントしてデータを展開しているなら`/content/drive/MyDrive`などと設定）\n",
    "OUTPUT_DIR = '.'  # 結果などを保存するフォルダ（ここではカレントフォルダを指定. Google Colaboratoryを使っていてGoogle Driveをマウントしてデータを展開しているなら`/content/drive/MyDrive`などと設定）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa93b155",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1884b431",
   "metadata": {},
   "source": [
    "これから分析に使うためのデータファイル（主にCSVファイル）をプログラムに読み込む. データを読み込むことで, Pythonからデータの中身を調べたり, いろいろな分析をできるようになる. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0899719",
   "metadata": {},
   "source": [
    "### 学習用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4523470f",
   "metadata": {},
   "source": [
    "学習用として与えられているのは`./train`以下にあるEEGの系列データと対応するラベル情報`train_master.csv`である. 以下の処理を行う.\n",
    "\n",
    "- 分類で使うラベル名と番号（id）を対応させて定義する.\n",
    "- 学習用データ（EEGデータ）ファイルを1つずつ読み込み, `np.array`形式のデータセット（train_X, train_y）を作る.\n",
    "- 読み込んだデータの中身や, サンプル数, チャンネル数, 系列長, データ型などの特徴を確認する.\n",
    "\n",
    "これらは機械学習モデリングを行うための準備である."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923755bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データファイルの場所（ファイル名：train_master.csv）を指定します\n",
    "data_path = os.path.join(DATA_DIR, 'train_master.csv')\n",
    "\n",
    "# pandasのread_csvを使って, ファイルを読み込みます\n",
    "train_df = pd.read_csv(data_path)\n",
    "\n",
    "# ちゃんと読み込めたか, 最初の5行を表示して確認します\n",
    "print(train_df.head(), '\\n')\n",
    "\n",
    "# ラベルごとに名前を割り当ててdictで定義します. 安静時(nonactive)は0, 運動想起時(active)は1.\n",
    "id2label = {0: 'nonactive', 1: 'active'}\n",
    "\n",
    "# 辞書データの内容をprintで確認\n",
    "print('labels:', id2label, '\\n')\n",
    "\n",
    "# 学習用の音声データを1ファイルずつ読み込み, リストとしてデータセットを作成します\n",
    "train_X = []  # 入力データを入れるリスト\n",
    "train_y = []  # 対応するラベルidを入れるリスト\n",
    "\n",
    "for i, d in train_df.iterrows():  # 学習用データフレーム（train_df）から1行ずつ取り出す\n",
    "    fpath = os.path.join(DATA_DIR, 'train', d['id']+'.csv')  # ファイルのパスを作成\n",
    "    x = pd.read_csv(fpath, header=None)  # データ(csv)を読み込む\n",
    "    numna = x.isna().sum().sum() # 欠損の確認\n",
    "    if numna:\n",
    "        print(i, 'includes na', numna)\n",
    "    train_X.append(x.values.T)  # データを追加\n",
    "    train_y.append(d['label'])  # ラベルを追加\n",
    "\n",
    "# リストをnumpy配列に変換（機械学習で使いやすい形）\n",
    "train_X = np.array(train_X)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "# データの特徴や配列サイズなどを確認\n",
    "n_samples, num_channels, seq_len = train_X.shape  # サンプル数とチャンネル数と系列長\n",
    "dtype = train_X.dtype  # データ型\n",
    "\n",
    "print('min:', train_X.min(), 'max:', train_X.max())  # 最小・最大値\n",
    "print('n_samples:', n_samples)  # サンプル数\n",
    "print('num_channels:', num_channels) # チャンネル数\n",
    "print('seq_len:', seq_len) # 系列データの長さ\n",
    "print('dtype:', dtype)  # データ型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4f2c7f",
   "metadata": {},
   "source": [
    "### 評価用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3507879",
   "metadata": {},
   "source": [
    "評価用として与えられているのは`./test`以下にあるEEGの系列データのみである. ラベル情報は与えられず, このラベルを当てることが今回の課題の主目的である. ここでは学習用データと同様に以下の処理を行う.\n",
    "\n",
    "- テスト用（評価用）のEEGデータファイルをすべて読み込み, np.array形式の配列（test_X）を作る.\n",
    "- 各ファイルのid（ファイル名から取得）もリスト（test_id）として記録する.\n",
    "- 読み込んだデータのサイズやidリストを表示し, 正しく取り込めたか確認する.\n",
    "\n",
    "これらは学習した機械学習モデルによって評価用データに対して推論を行って, 結果を作成するための準備である."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3928e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = []  # ファイルごとのidを入れるリスト\n",
    "test_X = []   # 脳波データ本体を入れるリスト\n",
    "\n",
    "# testフォルダにある全てのファイルをid順に処理します\n",
    "for p in sorted(os.listdir(os.path.join(DATA_DIR, 'test'))):  # ファイル名で順に並べる\n",
    "    fpath = os.path.join(DATA_DIR, 'test', p)  # ファイルのパスを作成\n",
    "    x = pd.read_csv(fpath, header=None)  # ファイルを読み込む\n",
    "    test_X.append(x.values.T)             # データ本体をリストに追加（転置して(チャンネル数×系列長)に）\n",
    "    test_id.append(p.split('.')[0])       # ファイル名からid部分だけ抜き出してリストに追加\n",
    "\n",
    "# リストをnumpy配列に変換します\n",
    "test_X = np.array(test_X)\n",
    "\n",
    "# 読み込んだデータの形状・idリストを表示して確認します\n",
    "print(test_X.shape)  # データの形（サンプル数 × チャンネル数 ×長さ）\n",
    "print(test_id)       # ファイルのidリスト"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20240dd",
   "metadata": {},
   "source": [
    "## 可視化・前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c759f6",
   "metadata": {},
   "source": [
    "読み込んだデータを可視化したり, 適切な前処理を行う."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca00d64",
   "metadata": {},
   "source": [
    "### 波形の可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2af244",
   "metadata": {},
   "source": [
    "学習データのうち1つのサンプルについて, 波形（時間と振幅のグラフ）を表示する. 波形を可視化することで, データの特徴やノイズ, 異常がないかを直感的に確認できる."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7506b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 100          # サンプリングレート（1秒あたりのデータ数）\n",
    "length = 500      # 可視化するデータ数（5秒分）\n",
    "idx = 0           # 可視化したいサンプルのインデックス（0番目を指定）\n",
    "\n",
    "# チャンネル名と型\n",
    "ch_names = [f'EEG {i}' for i in range(num_channels)]\n",
    "ch_types = ['eeg'] * num_channels\n",
    "\n",
    "# Infoの作成\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=sr, ch_types=ch_types) # type: ignore\n",
    "\n",
    "# RawArrayの作成\n",
    "raw = mne.io.RawArray(train_X[idx]*1e-6, info) # [μV]から[V]に変換\n",
    "\n",
    "# 生データの可視化\n",
    "raw.plot(n_channels=num_channels, scalings='auto', title='EEG from NumPy array')\n",
    "\n",
    "plt.show() # グラフ表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b669ea4f",
   "metadata": {},
   "source": [
    "`idx`を変えてほかのサンプルの波形も確認してみるとよい. 他にもパワースペクトル密度の可視化などさらなる詳細な分析も可能. 詳しくは[mneのチュートリアル](https://mne.tools/stable/auto_tutorials/index.html)を参照すること."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ecf2b6",
   "metadata": {},
   "source": [
    "### ラベルの分布可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ca9683",
   "metadata": {},
   "source": [
    "学習データに含まれるラベル（クラス）がどれくらいの数ずつあるかを棒グラフで可視化する. データの偏り（クラスバランス）があるかどうかを事前に確認するためのステップである."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324cf893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各ラベルごとの件数を集計します\n",
    "vals, cnts = np.unique(train_y, return_counts=True)  # ラベルIDごとのユニーク値とそれぞれの出現回数を取得\n",
    "\n",
    "# ラベルIDをラベル名（文字列）に変換します\n",
    "names = [id2label.get(v, f\"ID{v}\") for v in vals]\n",
    "\n",
    "# 棒グラフを作成して、ラベルごとの個数を可視化\n",
    "plt.figure(figsize=(8,4))  # グラフのサイズを指定\n",
    "plt.bar(names, cnts, width=0.8, align='center')  # 横軸＝ラベル名、縦軸＝件数\n",
    "plt.xlabel('label name')    # x軸ラベル\n",
    "plt.ylabel('count')         # y軸ラベル\n",
    "plt.show()                  # グラフ表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55d85de",
   "metadata": {},
   "source": [
    "### 前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9096003a",
   "metadata": {},
   "source": [
    "各サンプルごとに, 波形データの平均が0, 標準偏差が1になるように標準化（正規化）する. これにより, 値のスケールの違いが学習に影響しにくくなり, 分析や機械学習でより良い結果が得やすくなる."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacc772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 学習用データの前処理 ---\n",
    "# 前処理済みのデータを保存するための配列を用意（サイズは元データと同じ）\n",
    "train_X_preprocessed = np.zeros((n_samples, num_channels, seq_len))\n",
    "\n",
    "\n",
    "# 各サンプルごとに標準化（平均を0、標準偏差を1に）を行う\n",
    "for i in range(len(train_X)):\n",
    "    # 平均を引いて値を0中心にし、標準偏差で割って値のばらつきを揃える\n",
    "    train_x = np.where(np.isnan(train_X[i]), np.nanmean(train_X[i]), train_X[i]) # 欠損値は平均値で補完する\n",
    "    mean = train_x.mean(axis=1, keepdims=True)\n",
    "    std = train_x.std(axis=1, keepdims=True)\n",
    "    std[np.where(std==0)] = 1\n",
    "    train_X_preprocessed[i] = (train_x - mean) / std\n",
    "print(train_X_preprocessed.shape)\n",
    "\n",
    "# --- 評価用データの前処理 ---\n",
    "# 前処理済みのデータを保存するための配列を用意（サイズは元データと同じ）\n",
    "test_n_samples, num_channels, seq_len = test_X.shape # type: ignore\n",
    "test_X_preprocessed = np.zeros((test_n_samples, num_channels, seq_len))\n",
    "\n",
    "# 各サンプルごとに標準化（平均を0、標準偏差を1に）を行う\n",
    "for i in range(len(test_X)):\n",
    "    # 平均を引いて値を0中心にし、標準偏差で割って値のばらつきを揃える\n",
    "    test_x = np.where(np.isnan(test_X[i]), np.nanmean(test_X[i]), test_X[i]) # 欠損値は平均値で補完する\n",
    "    mean = test_x.mean(axis=1, keepdims=True)\n",
    "    std = test_x.std(axis=1, keepdims=True)\n",
    "    std[np.where(std==0)] = 1\n",
    "    test_X_preprocessed[i] = (test_x - mean) / std\n",
    "print(test_X_preprocessed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d090db55",
   "metadata": {},
   "source": [
    "## モデル構築・学習"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f56da4",
   "metadata": {},
   "source": [
    "学習データを使って, 運動意図を予測できるように深層学習モデルを学習させる. ここではShallowFBCSPNetというモデルを使い, データを訓練・検証に分けて自動で評価も行う."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd0c557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 深層学習モデル(ShallowFBCSPNet)を作成\n",
    "# - batch_size: 学習時に一度に使うサンプル数\n",
    "# - max_epochs: 学習の繰り返し回数\n",
    "# - train_split: 学習データの25%を検証用として自動で分ける\n",
    "net = EEGClassifier(\n",
    "    \"ShallowFBCSPNet\",\n",
    "    batch_size=32,\n",
    "    max_epochs=20,\n",
    "    train_split=ValidSplit(0.25) # 検証データ割合 # type: ignore\n",
    ")\n",
    "\n",
    "# 学習データ（train_X_preprocessed, train_y）を使ってモデルを訓練\n",
    "net.fit(train_X_preprocessed, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1599f924",
   "metadata": {},
   "source": [
    "`braindecode`にはほかにも脳波デコードモデルが実装されている. 興味があれば下記公式ページを参照されたい.\n",
    "\n",
    "- https://braindecode.org/stable/models/models_table.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9e2832",
   "metadata": {},
   "source": [
    "## 応募用ファイル作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f7c2be",
   "metadata": {},
   "source": [
    "学習済みモデルで評価用データのラベルを予測し, 指定されたフォーマットで予測結果（提出用ファイル）をCSV形式で保存する."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71ca56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習済みモデル（net）をCPUに移動\n",
    "# （GPUで学習した場合でも、推論時にCPUで動かすことで予測が可能になる）\n",
    "net.module_.cpu()\n",
    "\n",
    "# 評価用データ（test_X_preprocessed）でラベル予測を行う\n",
    "y_pred = net.predict(test_X_preprocessed)\n",
    "\n",
    "# 予測ラベルとtest_idをまとめて提出用データフレームを作成\n",
    "submit = pd.DataFrame({'test_id': test_id, 'y_pred': y_pred})\n",
    "\n",
    "# データフレームをCSVファイルとして保存\n",
    "# header=False, index=Falseとすることで余計な列名やインデックスを省略した提出用ファイルになる\n",
    "submit.to_csv(os.path.join(OUTPUT_DIR, 'submit.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da050128",
   "metadata": {},
   "source": [
    "作成した`./submit.csv`をコンペティションサイトに投稿することで, スコアが計算され, リーダーボードに順位がついて確認ができる.\n",
    "\n",
    "応募用ファイルの詳細なフォーマットについては`README.pdf`を参照すること."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb50005",
   "metadata": {},
   "source": [
    "## 深層学習の実装時によくある注意点・Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc24ceb",
   "metadata": {},
   "source": [
    "\n",
    "- **データのshape（形）に要注意！**  \n",
    "    モデルが要求するshape（例：(サンプル数, チャンネル数, 系列長)）になっているかを, `.shape`で確認.\n",
    "\n",
    "- **標準化などの前処理は、学習用・評価用どちらにも必ず同じ手順を！**  \n",
    "    前処理の違いで急激に精度が落ちることがある.\n",
    "\n",
    "- **モデルをGPUで学習した場合は、推論や保存時に `net.module_.cpu()` でCPUに戻すのを忘れずに！**\n",
    "\n",
    "- **`batch_size`や`max_epochs`を大きくしすぎるとメモリ不足や学習が極端に遅くなることがあるので注意**\n",
    "\n",
    "- **NaNやinfが出た場合は、データに異常値やゼロ割りがないか、標準化ロジックに問題がないかを確認する**\n",
    "\n",
    "- **バリデーション（検証）データの割合は、おおよそ0.2～0.3が一般的（今回の0.25は標準的）**\n",
    "\n",
    "- **深層学習モデルの学習は何度も試行錯誤！パラメータやネット構造をこまめに変えて実験しよう**\n",
    "\n",
    "\n",
    "困ったときは「shapeの確認」「前処理の共通化」「エラーメッセージをよく読む」の3点をまず確認すること."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc025809",
   "metadata": {},
   "source": [
    "## 発展：さらに高度な手法にチャレンジしたい方へ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f2b7df",
   "metadata": {},
   "source": [
    "- **独自のニューラルネットワーク構造を自作してみたい**\n",
    "    - 色々あるが, PyTorchが一般的によく使われるライブラリである.\n",
    "    - PyTorchの`torch.nn.Module`を継承すれば, 自由なネットワーク（CNN, RNN, Attention付きなど）を0から定義できる.\n",
    "    - 活性化関数や正則化（Dropoutなど）, 損失関数, 最適化アルゴリズムも自分で選んで組み合わせられる.\n",
    "\n",
    "- **skorchやbraindecodeのラッパークラスではなく, PyTorch単体でモデル作成・学習ループも実装できる**\n",
    "    - より細かく学習の流れをコントロールしたいときに有効.\n",
    "\n",
    "- **モデルアーキテクチャの参考や実装はPyTorch公式チュートリアルやKaggleの上位ノートなどもおすすめ**\n",
    "    - 公式：https://pytorch.org/tutorials/\n",
    "    - Kaggle: https://www.kaggle.com/search?q=pytorch+notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
